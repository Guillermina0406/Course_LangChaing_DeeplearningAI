#  LangChain: Fundamentos para la Construcci贸n de Aplicaciones con LLM

Este repositorio contiene una serie de cuadernos Jupyter que exploran los **bloques de construcci贸n fundamentales** para crear aplicaciones robustas y modulares con Large Language Models (**LLMs**) utilizando la librer铆a **LangChain** y la API de **OpenAI**.

##  Objetivos del Proyecto

El objetivo principal es pasar de las llamadas directas a la API de OpenAI a un enfoque estructurado y modular, aprendiendo a gestionar el **contexto** (Memoria), el **flujo** (Cadenas) y la **estructura de datos** (Parsers).

---

## 锔 Estructura del Repositorio y Conceptos Clave

| Cuaderno | Conceptos Cubiertos | Enfoque Principal |
| :--- | :--- | :--- |
| `L1-Model_prompt_parser.ipynb` | Modelos, Prompts y Parsers de Salida | **Estructuraci贸n de la Entrada y Salida (I/O).** |
| `L2-Memory.ipynb` | Tipos de Memoria | **Persistencia del Contexto Conversacional.** |
| `L3-Chains.ipynb` | Tipos de Cadenas (*Chains*) | **Automatizaci贸n de Flujos de Trabajo Inteligentes.** |

---

## 1.  M贸dulo de I/O: Modelos, Prompts y Parsers (L1)

Este m贸dulo cubre la preparaci贸n de la entrada para el LLM y la interpretaci贸n de su salida.

| Componente | Funci贸n T茅cnica | Prop贸sito Sencillo |
| :--- | :--- | :--- |
| **Prompts** | Clase `ChatPromptTemplate`. Define plantillas con *placeholders* (`{variable}`) para crear instrucciones reutilizables. | Separar la **instrucci贸n fija** (la tarea) de las **entradas variables** (el texto del usuario, el estilo). |
| **Output Parsers** | Clases `ResponseSchema` y `StructuredOutputParser`. Fuerza al LLM a generar una salida en formato **JSON** y la convierte en un objeto usable de Python (`dict`). | Tomar la respuesta del robot (que es texto) y convertirla en una **estructura de datos** f谩cil de manipular. |
| **Modelos (LLMs)** | Clase `ChatOpenAI`. Es la interfaz est谩ndar de LangChain para interactuar con los modelos de chat. | El "control remoto" para enviar y recibir datos del robot inteligente. |

---

## 2.  M贸dulo de Memoria (L2)

Este m贸dulo se enfoca en dotar a los *chatbots* de **contexto**, resolviendo el problema de que los LLMs son inherentemente "sin estado" (*stateless*).

| Tipo de Memoria | Funci贸n Principal | Control de Longitud |
| :--- | :--- | :--- |
| **`ConversationBufferMemory`** | Almacena el **historial completo**. | **Ninguno.** El historial crece indefinidamente. |
| **`ConversationTokenBufferMemory`** | Limita el historial seg煤n el **n煤mero total de *tokens*** consumidos. | **Estricto por Costo/Tama帽o.** Recorta mensajes antiguos para ajustarse al l铆mite. |
| **`ConversationSummaryBufferMemory`** | **Resume** las partes m谩s antiguas de la conversaci贸n (usando el LLM) y mantiene expl铆citas las interacciones recientes. | **Inteligente.** Mantiene el contexto relevante y el resumen informativo. |

---

## 3. 锔 M贸dulo de Cadenas (*Chains*) (L3)

El m贸dulo de Cadenas cubre la automatizaci贸n de flujos de trabajo al permitir enlazar m煤ltiples operaciones con LLMs. 

| Tipo de Cadena | Funci贸n Principal | Control de Flujo |
| :--- | :--- | :--- |
| **`LLMChain`** | La cadena m谩s b谩sica. Combina un LLM con una plantilla de prompt para una **tarea 煤nica**. | Directo. |
| **`SequentialChain`** | Permite **flujos de trabajo complejos** donde se combinan subcadenas con m煤ltiples entradas y salidas. | Secuencial (M煤ltiples entradas/salidas). |
| **`RouterChain`** | Utiliza un **Agente LLM** para analizar la entrada y **decidir a qu茅 subcadena especializada** debe enrutar la petici贸n. | **Decisi贸n Inteligente.** (Ej., enrutar preguntas de F铆sica a la cadena de F铆sica). |
